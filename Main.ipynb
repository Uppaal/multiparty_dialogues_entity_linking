{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ToDo\n",
    "***Preprocessing:***\n",
    "- clean :\n",
    "    - rows with NaN?\n",
    "    - rows with inly punctuation?\n",
    "- ~~word embeddings from fasttext~~\n",
    "- ~~mention sequences~~\n",
    "- phi_1 : ~~embeddings of first 3 words in m~~\n",
    "- phi_2 : \n",
    "    - ~~embeddings of 3 proceeding words~~\n",
    "    - ~~embeddings of 3 succeeding words~~\n",
    "    - ~~avg embedings of all words in m~~\n",
    "- phi_3 : \n",
    "    - ~~Embeddings of 3 proceeding sentences~~\n",
    "    - ~~Embeddings of 1 succeeding sentence~~\n",
    "    - ~~Embedding of the current sentence~~\n",
    "- phi_4 : \n",
    "    - ~~Embeddings of 3 proceeding utterances~~\n",
    "    - ~~Embeddings of 1 succeeding utterances~~\n",
    "    - ~~Embeddings of the current utterance~~\n",
    "- ~~embeddings~~\n",
    "- put everything in np arrays\n",
    "- get_features function\n",
    "- main function\n",
    "- episode and scene differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import fasttext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def __main__():\n",
    "    ## hyperparameters ##\n",
    "    embeddings_size = 50\n",
    "    text_transcript = 'data/text_transcript.txt'\n",
    "    ## main ##\n",
    "    train = pd.read_csv('data/friends.train.episode_delim.conll',sep='\\s+',header=None,comment='#')\n",
    "    train_scene = pd.read_csv('data/friends.train.scene_delim.conll',sep='\\s+',header=None,comment='#')\n",
    "    trial = pd.read_csv('data/friends.trial.episode_delim.conll',sep='\\s+',header=None,comment='#')\n",
    "    trial_scene = pd.read_csv('data/friends.trial.scene_delim.conll',sep='\\s+',header=None,comment='#')\n",
    "    dfs = [train,train_scene,trial,trial_scene]\n",
    "    dfs = [clean(df) for df in dfs]\n",
    "    with open(text_transcript,'wt') as f:\n",
    "        f.write(make_transcript(dfs))\n",
    "    embeddings_model = fasttext.skipgram(text_transcript,'embeddings_model',min_count=1,dim=50)\n",
    "    feature_matrices = []\n",
    "    for df in dfs:\n",
    "        feature_matrices.append(make_feature_matrices(train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_transcript(dfs,idx=6):\n",
    "    words = ''\n",
    "    for df in dfs:\n",
    "        words += ' '.join(list(df[idx]))\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean(df):\n",
    "    df = df[[0,2,3,4,5,6,9,10,11]]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_mention_rows(df):\n",
    "    return df[df[11]!='-'][df[11]!='NaN'][df[11]!=np.nan]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_words(df):\n",
    "    l = df[6].values\n",
    "    return l, range(len(l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_pre_words(mentions_idx,words,words_idx):\n",
    "    pre_words = []\n",
    "    for idx in mentions_idx:\n",
    "        pre_words.append([\\\n",
    "                           words[words_idx[idx[0]-1]] if (idx[-1]-1)>=0 else '',\\\n",
    "                           words[words_idx[idx[0]-2]] if (idx[-1]-2)>=0 else '',\\\n",
    "                           words[words_idx[idx[0]-3]] if (idx[-1]-3)>=0 else ''\\\n",
    "                          ])\n",
    "    return pre_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_next_words(mentions_idx,words,words_idx):\n",
    "    next_words = []\n",
    "    for idx in mentions_idx:\n",
    "        next_words.append([\\\n",
    "                           words[words_idx[idx[0]+1]] if (idx[-1]+1)<len(words) else '',\\\n",
    "                           words[words_idx[idx[0]+2]] if (idx[-1]+2)<len(words) else '',\\\n",
    "                           words[words_idx[idx[0]+3]] if (idx[-1]+3)<len(words) else ''\\\n",
    "                          ])\n",
    "    return next_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_sent_idx(df):\n",
    "    sents = []\n",
    "    sents_idx = []\n",
    "    cnt = 0\n",
    "    for row_no,row in df.iterrows():\n",
    "        if row[2]==0:\n",
    "            if row_no!=0:\n",
    "                cnt +=1\n",
    "                sents.append(sent_buf)\n",
    "            sent_buf = row[6]\n",
    "        else:\n",
    "            sent_buf += ' ' + row[6]\n",
    "        sents_idx.append(cnt)\n",
    "    if df.iloc[len(df)-1][2]!=0:\n",
    "        sents.append(sent_buf)\n",
    "        sents_idx.append(cnt)\n",
    "    return sents,sents_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_utterances_idx(df):\n",
    "    ut = []\n",
    "    ut_idx = []\n",
    "    cnt = 0\n",
    "    speaker = None\n",
    "    for row_no,row in df.iterrows():\n",
    "        if row[9]!=speaker:\n",
    "            if row_no!=0:\n",
    "                ut.append(ut_buf)\n",
    "                cnt += 1\n",
    "            speaker = row[9]\n",
    "            ut_buf = row[6]\n",
    "        else:\n",
    "            ut_buf += ' ' + row[6]\n",
    "        ut_idx.append(cnt)\n",
    "    if df.iloc[len(df)-1][9]==speaker:\n",
    "        ut.append(ut_buf)\n",
    "        ut_idx.append(cnt)\n",
    "    return ut,ut_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_mention_arrays(df):\n",
    "    mentions = []\n",
    "    mentions_y = []\n",
    "    mentions_idx = []\n",
    "    mention_f = False\n",
    "    for row_no,row in df.iterrows():\n",
    "        if mention_f and row[11]=='-':\n",
    "            mention_buf += ' ' + row[6]\n",
    "        elif row[11]=='-' or type(row[11])==float:\n",
    "            continue\n",
    "        elif ('(' in row[11]) and (')' in row[11]):\n",
    "            mentions.append(row[6])\n",
    "            mentions_y.append(int(row[11][1:-1]))\n",
    "            mentions_idx.append([row_no,row_no])\n",
    "        elif ('(' in row[11]):\n",
    "            mention_f = True\n",
    "            mention_buf = row[6]\n",
    "            mention_idx_buf = row_no\n",
    "        elif (')' in row[11]):\n",
    "            mention_f = False\n",
    "            mention_buf += ' ' + row[6]\n",
    "            mentions.append(mention_buf)\n",
    "            mentions_y.append(int(row[11][:-1]))\n",
    "            mentions_idx.append([mention_idx_buf,row_no])\n",
    "    return mentions,mentions_y,mentions_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_current_sents(mentions_idx,sents,sents_idx):\n",
    "    curr_sents = []\n",
    "    for idx in mentions_idx:\n",
    "        curr_sents.append(sents[sents_idx[idx[0]]])\n",
    "    return curr_sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_next_sents(mentions_idx,sents,sents_idx):\n",
    "    next_sents = []\n",
    "    for idx in mentions_idx:\n",
    "        t = sents_idx[idx[-1]]+1\n",
    "        if t<len(sents):\n",
    "            next_sents.append(sents[t])\n",
    "    return next_sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_pre_sents(mentions_idx,sents,sents_idx):\n",
    "    pre_sents = []\n",
    "    for idx in mentions_idx:\n",
    "        t = sents_idx[idx[0]]\n",
    "        pre_sents.append([\\\n",
    "                         sents[t-1] if (t-1)>=0 else '',\\\n",
    "                          sents[t-2] if (t-2)>=0 else '',\\\n",
    "                          sents[t-3] if (t-3)>=0 else ''\\\n",
    "                         ])\n",
    "    return pre_sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_current_utterance(mentions_idx,ut,ut_idx):\n",
    "    curr_ut = []\n",
    "    for idx in mentions_idx:\n",
    "        curr_ut.append(ut[ut_idx[idx[0]]])\n",
    "    return curr_ut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_next_utterances(mentions_idx,ut,ut_idx):\n",
    "    next_ut = []\n",
    "    for idx in mentions_idx:\n",
    "        t = ut_idx[idx[-1]]+1\n",
    "        if t<len(ut):\n",
    "            next_ut.append(ut[t])\n",
    "    return next_ut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_pre_utterances(mentions_idx,ut,ut_idx):\n",
    "    pre_ut = []\n",
    "    for idx in mentions_idx:\n",
    "        t = ut_idx[idx[0]]\n",
    "        pre_ut.append([\\\n",
    "                         ut[t-1] if (t-1)>=0 else '',\\\n",
    "                          ut[t-2] if (t-2)>=0 else '',\\\n",
    "                          ut[t-3] if (t-3)>=0 else ''\\\n",
    "                         ])\n",
    "    return pre_ut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_embeddings(l):\n",
    "    return np.array([embeddings_model[i] for i in l])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_avg_embeddings(l):\n",
    "    a = [np.array([embeddings_model[i] for i in sent.split()]) for sent in l]\n",
    "    return np.array([np.sum(i,axis=0)/len(i) for i in a])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_multiple_avg_embeddings(l):\n",
    "    ret = []\n",
    "    for sent_arr in l:\n",
    "        sent_arr_emb = []\n",
    "        for sent in sent_arr:\n",
    "            if sent=='':\n",
    "                sent_arr_emb.append([0]*embeddings_size)\n",
    "            else:\n",
    "                sent_emb = []\n",
    "                for word in sent.split():\n",
    "                    sent_emb.append(embeddings_model[word])\n",
    "                sent_arr_emb.append(np.sum(sent_emb,axis=0)/len(sent_emb))\n",
    "        ret.append(sent_arr_emb)\n",
    "    return np.array(ret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('data/friends.train.episode_delim.conll',sep='\\s+',header=None,comment='#')\n",
    "df = clean(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mentions,mentions_y,mentions_idx = get_mention_arrays(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "words,words_idx = get_words(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pre_words = get_pre_words(mentions_idx,words,words_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "next_words = get_next_words(mentions_idx,words,words_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sents,sents_idx = get_sent_idx(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "curr_sents = get_current_sents(mentions_idx,sents,sents_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "next_sents = get_next_sents(mentions_idx,sents,sents_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pre_sents = get_pre_sents(mentions_idx,sents,sents_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ut,ut_idx = get_utterances_idx(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "curr_ut = get_current_utterance(mentions_idx,ut,ut_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "next_ut = get_next_utterances(mentions_idx,ut,ut_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pre_ut = get_pre_utterances(mentions_idx,ut,ut_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_phi_1(mentions):\n",
    "    phi = []\n",
    "    for i in mentions:\n",
    "        t = i.split()\n",
    "        if len(t)==0:\n",
    "            raise ValueError('Empty mention')\n",
    "        elif len(t)==1:\n",
    "            phi.append(get_embeddings(t+['','']))\n",
    "        elif len(t)==2:\n",
    "            phi.append(get_embeddings(t+['']))\n",
    "        else:\n",
    "            phi.append(get_embeddings(t[0:3]))\n",
    "    return np.array(phi)\n",
    "\n",
    "def get_phi_2(pre_words,next_words,mentions):\n",
    "    pre = [get_embeddings(i) for i in pre_words]\n",
    "    suc = [get_embeddings(i) for i in next_words]\n",
    "    avg = get_avg_embeddings(mentions)\n",
    "    return np.array([np.vstack((i[0],i[1],i[2],j[0],j[1],j[2],k)) for i,j,k in zip(pre,suc,avg)])\n",
    "\n",
    "def get_phi_3(pre_sents,next_sents,curr_sents):\n",
    "    p = get_multiple_avg_embeddings(pre_sents)\n",
    "    s = get_avg_embeddings(next_sents)\n",
    "    c = get_avg_embeddings(curr_sents)\n",
    "    return np.array([np.vstack((i[0],i[1],i[2],j,k)) for i,j,k in zip(p,s,c)])\n",
    "\n",
    "def get_phi_4(pre_ut,next_ut,curr_ut):\n",
    "    p = get_multiple_avg_embeddings(pre_ut)\n",
    "    s = get_avg_embeddings(next_ut)\n",
    "    c = get_avg_embeddings(curr_ut)\n",
    "    return np.array([np.vstack((i[0],i[1],i[2],j,k)) for i,j,k in zip(p,s,c)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "phi = [0]*5\n",
    "phi[1] = get_phi_1(mentions)\n",
    "phi[2] = get_phi_2(pre_words,next_words,mentions)\n",
    "phi[3] = get_phi_3(pre_sents,next_sents,curr_sents)\n",
    "phi[4] = get_phi_4(pre_ut,next_ut,curr_ut)\n",
    "phi[1] = np.reshape(phi[1],[13280,3,50,1])\n",
    "phi[2] = np.reshape(phi[2],[13280,7,50,1])\n",
    "phi[3] = np.reshape(phi[3],[13280,5,50,1])\n",
    "phi[4] = np.reshape(phi[4],[13280,5,50,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_mention_pairs(phi,mentions_y,window=7):\n",
    "    tuples = []\n",
    "    for i in range(len(phi[1])):\n",
    "        for j in range(i+1,window+i+1):\n",
    "            if j<len(phi[1]):\n",
    "                tuples.append([\\\n",
    "                              [phi[k][i] for k in range(1,5)],\\\n",
    "                              [phi[k][j] for k in range(1,5)],\\\n",
    "                              1 if mentions_y[i]==mentions_y[j] else 0\\\n",
    "                             ])\n",
    "            else:\n",
    "                break\n",
    "    return tuples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pairs = make_mention_pairs(phi,mentions_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "92932"
      ]
     },
     "execution_count": 475,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "92960"
      ]
     },
     "execution_count": 477,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "13280*7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import fasttext\n",
    "model = fasttext.skipgram('data/001.txt','model',min_count=1,dim=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embeddings_model = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('data/001.txt','rt') as f:\n",
    "    l = f.read().split('\\n\\n')\n",
    "    a = get_avg_embeddings(l)\n",
    "    print(len(l),len(a))\n",
    "    print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.options.display.max_rows = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/friends-s01e01</td>\n",
       "      <td>0</td>\n",
       "      <td>There</td>\n",
       "      <td>EX</td>\n",
       "      <td>(TOP(S(NP*)</td>\n",
       "      <td>there</td>\n",
       "      <td>Monica_Geller</td>\n",
       "      <td>*</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/friends-s01e01</td>\n",
       "      <td>1</td>\n",
       "      <td>'s</td>\n",
       "      <td>VBZ</td>\n",
       "      <td>(VP*</td>\n",
       "      <td>be</td>\n",
       "      <td>Monica_Geller</td>\n",
       "      <td>*</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160169</th>\n",
       "      <td>/friends-s02e24</td>\n",
       "      <td>5</td>\n",
       "      <td>girl</td>\n",
       "      <td>NN</td>\n",
       "      <td>*))</td>\n",
       "      <td>girl</td>\n",
       "      <td>Joey_Tribbiani</td>\n",
       "      <td>*</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160170</th>\n",
       "      <td>/friends-s02e24</td>\n",
       "      <td>6</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>*))</td>\n",
       "      <td>.</td>\n",
       "      <td>Joey_Tribbiani</td>\n",
       "      <td>*</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>160171 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     0   2      3    4            5      6               9   \\\n",
       "0       /friends-s01e01   0  There   EX  (TOP(S(NP*)  there   Monica_Geller   \n",
       "1       /friends-s01e01   1     's  VBZ         (VP*     be   Monica_Geller   \n",
       "...                 ...  ..    ...  ...          ...    ...             ...   \n",
       "160169  /friends-s02e24   5   girl   NN          *))   girl  Joey_Tribbiani   \n",
       "160170  /friends-s02e24   6      .    .          *))      .  Joey_Tribbiani   \n",
       "\n",
       "       10 11  \n",
       "0       *  -  \n",
       "1       *  -  \n",
       "...    .. ..  \n",
       "160169  *  -  \n",
       "160170  *  -  \n",
       "\n",
       "[160171 rows x 9 columns]"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('remove_me.txt','wt') as f:\n",
    "    print(df,file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
