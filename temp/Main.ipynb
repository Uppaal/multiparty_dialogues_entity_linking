{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ToDo\n",
    "***Preprocessing:***\n",
    "- clean :\n",
    "    - rows with NaN?\n",
    "    - rows with inly punctuation?\n",
    "- ~~word embeddings from fasttext~~\n",
    "- ~~mention sequences~~\n",
    "- phi_1 : ~~embeddings of first 3 words in m~~\n",
    "- phi_2 : \n",
    "    - ~~embeddings of 3 proceeding words~~\n",
    "    - ~~embeddings of 3 succeeding words~~\n",
    "    - ~~avg embedings of all words in m~~\n",
    "- phi_3 : \n",
    "    - ~~Embeddings of 3 proceeding sentences~~\n",
    "    - ~~Embeddings of 1 succeeding sentence~~\n",
    "    - ~~Embedding of the current sentence~~\n",
    "- phi_4 : \n",
    "    - ~~Embeddings of 3 proceeding utterances~~\n",
    "    - ~~Embeddings of 1 succeeding utterances~~\n",
    "    - ~~Embeddings of the current utterance~~\n",
    "- ~~embeddings~~\n",
    "- put everything in np arrays\n",
    "- get_features function\n",
    "- main function\n",
    "- episode and scene differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "#import fasttext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def __main__():\n",
    "    ## hyperparameters ##\n",
    "    embeddings_size = 50\n",
    "    text_transcript = 'data/text_transcript.txt'\n",
    "    ## main ##\n",
    "    train = pd.read_csv('data/friends.train.episode_delim.conll',sep='\\s+',header=None,comment='#')\n",
    "    train_scene = pd.read_csv('data/friends.train.scene_delim.conll',sep='\\s+',header=None,comment='#')\n",
    "    trial = pd.read_csv('data/friends.trial.episode_delim.conll',sep='\\s+',header=None,comment='#')\n",
    "    trial_scene = pd.read_csv('data/friends.trial.scene_delim.conll',sep='\\s+',header=None,comment='#')\n",
    "    dfs = [train,train_scene,trial,trial_scene]\n",
    "    dfs = [clean(df) for df in dfs]\n",
    "    with open(text_transcript,'wt') as f:\n",
    "        f.write(make_transcript(dfs))\n",
    "    embeddings_model = fasttext.skipgram(text_transcript,'embeddings_model',min_count=1,dim=50)\n",
    "    feature_matrices = []\n",
    "    for df in dfs:\n",
    "        feature_matrices.append(make_feature_matrices(train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_transcript(dfs,idx=6):\n",
    "    words = ''\n",
    "    for df in dfs:\n",
    "        words += ' '.join(list(df[idx]))\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean(df):\n",
    "    df = df[[0,2,3,4,5,6,9,10,11]]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_mention_rows(df):\n",
    "    return df[df[11]!='-'][df[11]!='NaN'][df[11]!=np.nan]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_words(df):\n",
    "    l = df[6].values\n",
    "    return l, range(len(l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_pre_words(mentions_idx,words,words_idx):\n",
    "    pre_words = []\n",
    "    for idx in mentions_idx:\n",
    "        pre_words.append([\\\n",
    "                           words[words_idx[idx[0]-1]] if (idx[-1]-1)>=0 else '',\\\n",
    "                           words[words_idx[idx[0]-2]] if (idx[-1]-2)>=0 else '',\\\n",
    "                           words[words_idx[idx[0]-3]] if (idx[-1]-3)>=0 else ''\\\n",
    "                          ])\n",
    "    return pre_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_next_words(mentions_idx,words,words_idx):\n",
    "    next_words = []\n",
    "    for idx in mentions_idx:\n",
    "        next_words.append([\\\n",
    "                           words[words_idx[idx[0]+1]] if (idx[-1]+1)<len(words) else '',\\\n",
    "                           words[words_idx[idx[0]+2]] if (idx[-1]+2)<len(words) else '',\\\n",
    "                           words[words_idx[idx[0]+3]] if (idx[-1]+3)<len(words) else ''\\\n",
    "                          ])\n",
    "    return next_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_sent_idx(df):\n",
    "    sents = []\n",
    "    sents_idx = []\n",
    "    cnt = 0\n",
    "    for row_no,row in df.iterrows():\n",
    "        if row[2]==0:\n",
    "            if row_no!=0:\n",
    "                cnt +=1\n",
    "                sents.append(sent_buf)\n",
    "            sent_buf = row[6]\n",
    "        else:\n",
    "            sent_buf += ' ' + row[6]\n",
    "        sents_idx.append(cnt)\n",
    "    if df.iloc[len(df)-1][2]!=0:\n",
    "        sents.append(sent_buf)\n",
    "        sents_idx.append(cnt)\n",
    "    return sents,sents_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_utterances_idx(df):\n",
    "    ut = []\n",
    "    ut_idx = []\n",
    "    cnt = 0\n",
    "    speaker = None\n",
    "    for row_no,row in df.iterrows():\n",
    "        if row[9]!=speaker:\n",
    "            if row_no!=0:\n",
    "                ut.append(ut_buf)\n",
    "                cnt += 1\n",
    "            speaker = row[9]\n",
    "            ut_buf = row[6]\n",
    "        else:\n",
    "            ut_buf += ' ' + row[6]\n",
    "        ut_idx.append(cnt)\n",
    "    if df.iloc[len(df)-1][9]==speaker:\n",
    "        ut.append(ut_buf)\n",
    "        ut_idx.append(cnt)\n",
    "    return ut,ut_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mention_arrays(df):\n",
    "    mentions = []\n",
    "    mentions_y = []\n",
    "    mentions_idx = []\n",
    "    mention_f = False\n",
    "    for row_no,row in df.iterrows():\n",
    "        if mention_f and row[11]=='-':\n",
    "            mention_buf += ' ' + row[6]\n",
    "        elif row[11]=='-' or type(row[11])==float:\n",
    "            continue\n",
    "        elif ('(' in row[11]) and (')' in row[11]):\n",
    "            mentions.append(row[6])\n",
    "            mentions_y.append(int(row[11][1:-1]))\n",
    "            mentions_idx.append([row_no,row_no])\n",
    "        elif ('(' in row[11]):\n",
    "            mention_f = True\n",
    "            mention_buf = row[6]\n",
    "            mention_idx_buf = row_no\n",
    "        elif (')' in row[11]):\n",
    "            mention_f = False\n",
    "            mention_buf += ' ' + row[6]\n",
    "            mentions.append(mention_buf)\n",
    "            mentions_y.append(int(row[11][:-1]))\n",
    "            mentions_idx.append([mention_idx_buf,row_no])\n",
    "    return mentions,mentions_y,mentions_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_current_sents(mentions_idx,sents,sents_idx):\n",
    "    curr_sents = []\n",
    "    for idx in mentions_idx:\n",
    "        curr_sents.append(sents[sents_idx[idx[0]]])\n",
    "    return curr_sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_next_sents(mentions_idx,sents,sents_idx):\n",
    "    next_sents = []\n",
    "    for idx in mentions_idx:\n",
    "        t = sents_idx[idx[-1]]+1\n",
    "        if t<len(sents):\n",
    "            next_sents.append(sents[t])\n",
    "    return next_sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_pre_sents(mentions_idx,sents,sents_idx):\n",
    "    pre_sents = []\n",
    "    for idx in mentions_idx:\n",
    "        t = sents_idx[idx[0]]\n",
    "        pre_sents.append([\\\n",
    "                         sents[t-1] if (t-1)>=0 else '',\\\n",
    "                          sents[t-2] if (t-2)>=0 else '',\\\n",
    "                          sents[t-3] if (t-3)>=0 else ''\\\n",
    "                         ])\n",
    "    return pre_sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_current_utterance(mentions_idx,ut,ut_idx):\n",
    "    curr_ut = []\n",
    "    for idx in mentions_idx:\n",
    "        curr_ut.append(ut[ut_idx[idx[0]]])\n",
    "    return curr_ut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_next_utterances(mentions_idx,ut,ut_idx):\n",
    "    next_ut = []\n",
    "    for idx in mentions_idx:\n",
    "        t = ut_idx[idx[-1]]+1\n",
    "        if t<len(ut):\n",
    "            next_ut.append(ut[t])\n",
    "    return next_ut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_pre_utterances(mentions_idx,ut,ut_idx):\n",
    "    pre_ut = []\n",
    "    for idx in mentions_idx:\n",
    "        t = ut_idx[idx[0]]\n",
    "        pre_ut.append([\\\n",
    "                         ut[t-1] if (t-1)>=0 else '',\\\n",
    "                          ut[t-2] if (t-2)>=0 else '',\\\n",
    "                          ut[t-3] if (t-3)>=0 else ''\\\n",
    "                         ])\n",
    "    return pre_ut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_embeddings(l):\n",
    "    return np.array([embeddings_model[i] for i in l])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_avg_embeddings(l):\n",
    "    a = [np.array([embeddings_model[i] for i in sent.split()]) for sent in l]\n",
    "    return np.array([np.sum(i,axis=0)/len(i) for i in a])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_multiple_avg_embeddings(l):\n",
    "    ret = []\n",
    "    for sent_arr in l:\n",
    "        sent_arr_emb = []\n",
    "        for sent in sent_arr:\n",
    "            if sent=='':\n",
    "                sent_arr_emb.append([0]*embeddings_size)\n",
    "            else:\n",
    "                sent_emb = []\n",
    "                for word in sent.split():\n",
    "                    sent_emb.append(embeddings_model[word])\n",
    "                sent_arr_emb.append(np.sum(sent_emb,axis=0)/len(sent_emb))\n",
    "        ret.append(sent_arr_emb)\n",
    "    return np.array(ret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('data/friends.train.episode_delim.conll',sep='\\s+',header=None,comment='#')\n",
    "df = clean(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "mentions,mentions_y,mentions_idx = get_mention_arrays(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "words,words_idx = get_words(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_words = get_pre_words(mentions_idx,words,words_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "next_words = get_next_words(mentions_idx,words,words_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "sents,sents_idx = get_sent_idx(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_sents = get_current_sents(mentions_idx,sents,sents_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "next_sents = get_next_sents(mentions_idx,sents,sents_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_sents = get_pre_sents(mentions_idx,sents,sents_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "ut,ut_idx = get_utterances_idx(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "curr_ut = get_current_utterance(mentions_idx,ut,ut_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "next_ut = get_next_utterances(mentions_idx,ut,ut_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_ut = get_pre_utterances(mentions_idx,ut,ut_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_phi_1(mentions):\n",
    "    phi = []\n",
    "    for i in mentions:\n",
    "        t = i.split()\n",
    "        if len(t)==0:\n",
    "            raise ValueError('Empty mention')\n",
    "        elif len(t)==1:\n",
    "            phi.append(get_embeddings(t+['','']))\n",
    "        elif len(t)==2:\n",
    "            phi.append(get_embeddings(t+['']))\n",
    "        else:\n",
    "            phi.append(get_embeddings(t[0:3]))\n",
    "    return np.array(phi)\n",
    "\n",
    "def get_phi_2(pre_words,next_words,mentions):\n",
    "    pre = [get_embeddings(i) for i in pre_words]\n",
    "    suc = [get_embeddings(i) for i in next_words]\n",
    "    avg = get_avg_embeddings(mentions)\n",
    "    return np.array([np.vstack((i[0],i[1],i[2],j[0],j[1],j[2],k)) for i,j,k in zip(pre,suc,avg)])\n",
    "\n",
    "def get_phi_3(pre_sents,next_sents,curr_sents):\n",
    "    p = get_multiple_avg_embeddings(pre_sents)\n",
    "    s = get_avg_embeddings(next_sents)\n",
    "    c = get_avg_embeddings(curr_sents)\n",
    "    return np.array([np.vstack((i[0],i[1],i[2],j,k)) for i,j,k in zip(p,s,c)])\n",
    "\n",
    "def get_phi_4(pre_ut,next_ut,curr_ut):\n",
    "    p = get_multiple_avg_embeddings(pre_ut)\n",
    "    s = get_avg_embeddings(next_ut)\n",
    "    c = get_avg_embeddings(curr_ut)\n",
    "    return np.array([np.vstack((i[0],i[1],i[2],j,k)) for i,j,k in zip(p,s,c)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {},
   "outputs": [],
   "source": [
    "phi = [0]*5\n",
    "phi[1] = get_phi_1(mentions)\n",
    "phi[2] = get_phi_2(pre_words,next_words,mentions)\n",
    "phi[3] = get_phi_3(pre_sents,next_sents,curr_sents)\n",
    "phi[4] = get_phi_4(pre_ut,next_ut,curr_ut)\n",
    "phi[1] = np.reshape(phi[1],[13280,3,50,1])\n",
    "phi[2] = np.reshape(phi[2],[13280,7,50,1])\n",
    "phi[3] = np.reshape(phi[3],[13280,5,50,1])\n",
    "phi[4] = np.reshape(phi[4],[13280,5,50,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_mention_pairs(phi,mentions_y,window=7):\n",
    "    tuples = []\n",
    "    for i in range(len(phi[1])):\n",
    "        for j in range(i+1,window+i+1):\n",
    "            if j<len(phi[1]):\n",
    "                tuples.append([\\\n",
    "                              [phi[k][i] for k in range(1,5)],\\\n",
    "                              [phi[k][j] for k in range(1,5)],\\\n",
    "                              1 if mentions_y[i]==mentions_y[j] else 0\\\n",
    "                             ])\n",
    "            else:\n",
    "                break\n",
    "    return tuples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = make_mention_pairs(phi,mentions_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "92932"
      ]
     },
     "execution_count": 475,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "92960"
      ]
     },
     "execution_count": 477,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "13280*7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import fasttext\n",
    "model = fasttext.skipgram('data/001.txt','model',min_count=1,dim=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embeddings_model = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/001.txt','rt') as f:\n",
    "    l = f.read().split('\\n\\n')\n",
    "    a = get_avg_embeddings(l)\n",
    "    print(len(l),len(a))\n",
    "    print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.options.display.max_rows = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[                     0   1   2       3    4            5       6  7  8   \\\n",
       " 160161  /friends-s02e24   0   6       a   DT         (NP*       a  -  -   \n",
       " 160162  /friends-s02e24   0   7    kiss   NN        *))))    kiss  -  -   \n",
       " 160163  /friends-s02e24   0   8       .    .          *))       .  -  -   \n",
       " 160164  /friends-s02e24   0   0  Rachel  NNP  (TOP(S(NP*)  Rachel  -  -   \n",
       " 160165  /friends-s02e24   0   1      is  VBZ         (VP*      be  -  -   \n",
       " 160166  /friends-s02e24   0   2       a   DT         (NP*       a  -  -   \n",
       " 160167  /friends-s02e24   0   3    very   RB       (ADJP*    very  -  -   \n",
       " 160168  /friends-s02e24   0   4   lucky   JJ           *)   lucky  -  -   \n",
       " 160169  /friends-s02e24   0   5    girl   NN          *))    girl  -  -   \n",
       " 160170  /friends-s02e24   0   6       .    .          *))       .  -  -   \n",
       " \n",
       "                     9         10 11  \n",
       " 160161  Joey_Tribbiani         *  -  \n",
       " 160162  Joey_Tribbiani         *  -  \n",
       " 160163  Joey_Tribbiani         *  -  \n",
       " 160164  Joey_Tribbiani  (PERSON)  -  \n",
       " 160165  Joey_Tribbiani         *  -  \n",
       " 160166  Joey_Tribbiani         *  -  \n",
       " 160167  Joey_Tribbiani         *  -  \n",
       " 160168  Joey_Tribbiani         *  -  \n",
       " 160169  Joey_Tribbiani         *  -  \n",
       " 160170  Joey_Tribbiani         *  -  ,\n",
       "                      0   1   2        3    4         5        6  7  8   \\\n",
       " 111768  /friends-s02e24   8  15  fashion   NN      *)))  fashion  -  -   \n",
       " 111769  /friends-s02e24   8  16     were  VBD      (VP*       be  -  -   \n",
       " 111770  /friends-s02e24   8  17   always   RB  (ADVP*))   always  -  -   \n",
       " 111771  /friends-s02e24   8  18      the   DT   (NP(NP*      the  -  -   \n",
       " 111772  /friends-s02e24   8  19  passion   NN        *)  passion  -  -   \n",
       " 111773  /friends-s02e24   8  20        ,    ,         *        ,  -  -   \n",
       " 111774  /friends-s02e24   8  21       at   IN    (ADVP*       at  -  -   \n",
       " 111775  /friends-s02e24   8  22      the   DT      (NP*      the  -  -   \n",
       " 111776  /friends-s02e24   8  23     Copa   NN       *))     copa  -  -   \n",
       " 111777  /friends-s02e24   8  24     ....   CD  (NP*))))     ....  -  -   \n",
       " \n",
       "                   9         10 11  \n",
       " 111768  Rachel_Green         *  -  \n",
       " 111769  Rachel_Green         *  -  \n",
       " 111770  Rachel_Green         *  -  \n",
       " 111771  Rachel_Green         *  -  \n",
       " 111772  Rachel_Green         *  -  \n",
       " 111773  Rachel_Green         *  -  \n",
       " 111774  Rachel_Green         *  -  \n",
       " 111775  Rachel_Green         *  -  \n",
       " 111776  Rachel_Green         *  -  \n",
       " 111777  Rachel_Green  (NUMBER)  -  ,\n",
       "                    0   1   2       3    4          5       6  7  8   \\\n",
       " 7824  /friends-s01e02   0   8    shot   NN    *))))))    shot  -  -   \n",
       " 7825  /friends-s01e02   0   9       ,    ,          *       ,  -  -   \n",
       " 7826  /friends-s01e02   0  10     but   CC          *     but  -  -   \n",
       " 7827  /friends-s01e02   0  11       I  PRP    (S(NP*)       I  -  -   \n",
       " 7828  /friends-s01e02   0  12    feel  VBP       (VP*    feel  -  -   \n",
       " 7829  /friends-s01e02   0  13      so   RB       (NP*      so  -  -   \n",
       " 7830  /friends-s01e02   0  14    much   RB          *    much  -  -   \n",
       " 7831  /friends-s01e02   0  15  better  JJR         *)  better  -  -   \n",
       " 7832  /friends-s01e02   0  16     now   RB  (ADVP*)))     now  -  -   \n",
       " 7833  /friends-s01e02   0  17       .    .        *))       .  -  -   \n",
       " \n",
       "                 9       10 11  \n",
       " 7824  Rachel_Green       *  -  \n",
       " 7825  Rachel_Green       *  -  \n",
       " 7826  Rachel_Green       *  -  \n",
       " 7827  Rachel_Green       *  -  \n",
       " 7828  Rachel_Green       *  -  \n",
       " 7829  Rachel_Green       *  -  \n",
       " 7830  Rachel_Green       *  -  \n",
       " 7831  Rachel_Green       *  -  \n",
       " 7832  Rachel_Green  (DATE)  -  \n",
       " 7833  Rachel_Green       *  -  ,\n",
       "                    0   1   2       3    4            5      6  7  8       9   \\\n",
       " 5424  /friends-s01e02   6   1       ,    ,            *      ,  -  -   Barry   \n",
       " 5425  /friends-s01e02   6   2   thank   VB         (VP*  thank  -  -   Barry   \n",
       " 5426  /friends-s01e02   6   3     you  PRP        (NP*)    you  -  -   Barry   \n",
       " 5427  /friends-s01e02   6   4     for   IN         (PP*    for  -  -   Barry   \n",
       " 5428  /friends-s01e02   6   5  giving  VBG       (S(VP*   give  -  -   Barry   \n",
       " 5429  /friends-s01e02   6   6      it  PRP        (NP*)     it  -  -   Barry   \n",
       " 5430  /friends-s01e02   6   7    back   RB  (ADVP*)))))   back  -  -   Barry   \n",
       " 5431  /friends-s01e02   6   8       .    .          *))      .  -  -   Barry   \n",
       " 5432  /friends-s01e02   6   0   Hello   UH   (TOP(INTJ*  hello  -  -  Robbie   \n",
       " 5433  /friends-s01e02   6   1      ?!  SYM          *))     ?!  -  -  Robbie   \n",
       " \n",
       "      10     11  \n",
       " 5424  *      -  \n",
       " 5425  *      -  \n",
       " 5426  *  (306)  \n",
       " 5427  *      -  \n",
       " 5428  *      -  \n",
       " 5429  *      -  \n",
       " 5430  *      -  \n",
       " 5431  *      -  \n",
       " 5432  *      -  \n",
       " 5433  *      -  ]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[i[-10:] for i in dfs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('remove_me.txt','wt') as f:\n",
    "    print(df,file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_transcript = 'data/text_transcript.txt'\n",
    "## main ##\n",
    "train = pd.read_csv('data/friends.train.episode_delim.conll',sep='\\s+',header=None,comment='#')\n",
    "train_scene = pd.read_csv('data/friends.train.scene_delim.conll',sep='\\s+',header=None,comment='#')\n",
    "trial = pd.read_csv('data/friends.trial.episode_delim.conll',sep='\\s+',header=None,comment='#')\n",
    "trial_scene = pd.read_csv('data/friends.trial.scene_delim.conll',sep='\\s+',header=None,comment='#')\n",
    "dfs = [train,train_scene,trial,trial_scene]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  },
  "widgets": {
   "state": {},
   "version": "1.1.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
